# -*- eval: (flyspell-mode 0) -*-
#+title: Scaletta
* WAIT Introduzione
- Prendi spunto da: "BDGS: A Scalable Big Data Generator Suite in Big Data Benchmarking"
- parla della nascita del lavoro e di come è basato sulla valutazione delle performance di architetture destinate ad uso come Data Lake.
- parla del fatto che siamo concentrati sulle tecniche di modelling
- parla del fatto che non ci sono molti dataset a disposizione
- parla del fatto che quindi si opta di generare questi dati sinteticamente
- uno dei pochi dataset a disposizione che introduce abbastanza eterogeneità è MIMIC-III
- non ci sono molti tool a disposizione per simulare tracce simili a quelle di mimic
- ne creiamo uno, ma che imita le tempistiche, essendo interessati ai metodi di modelling.
- Nonostante questa limitazione, può già potenzialmente essere utilizzato su modelli destinati alla performance evaluation di Data Lakes [barbierato et al].
** Obiettivi del nostro lavoro
Costruire un simulatore che sia fine-tunable e adaptable
** Structure of the thesis
- parla del fatto che la tesi è stata divisa in due parti e spiega perché (vedi approach)
- indica la struttura formale (nel capitolo ... nel capitolo ...)

* TODO Stato dell'arte
* DONE Background
** DONE Mimic
*** DONE Origins
Beth Israel, time period
*** DONE What the dataset was designed to do/consists in
not performance analysis
Definizione *Event*
*** DONE Mimic deidentification
What is kept
*** NO Mimic III vs Mimic IV
**** NO Why did we chose Mimic III
*** DONE Demo + corso
*** DONE What it contains
Events mostly (also talk about dictionary tables etc)
**** DONE What do we mean when we say "events"
Describe how tuples are formed:
- row id
- a reference to the admission id
- eventually a reference to the icustay id
- eventually a timing value (we will mostly focus on events that have this attribute)
**** DONE List Mimic tables
**** DONE Waveforms
headers vs data
matched subset
*** NO Discrepancies found
** DONE Phase type distributions
*** versatilità
[cite:@bladtReviewPhasetypeDistributions2005]
** DONE Hyperstar
*** Come funziona e quale parte richiede l'interazione utente
** DONE Kolm-Smir test
*** Funzione che testa
*** Parametro di threshold
** JMT e JSimGraph
*** Queuing network
*** jobs and job classes
*** Performance indexes
*** NO Replayer

* NO Approach
** DONE Intro
*** DONE Thesis objective
**** thesis description
Questo lavore rivolve intorno l'analisi di un set di dati health-related dei pazienti di un'ospedale,
**** Obiettivi
- creazione di un modello delle interazioni
- rendere tale modello riutilizzabile
**** How it was born
Breve descrizione del progetto generale (benchmark)
**** Why is it useful
** Design decisions
*** The obstacle of mimic deidentification
**** what is deidentified (briefly)
**** how it influenced our work
We had to consider the patients singularly.

*** Two step work
(analysis + model creation)
**** why we need an analysis
to gain additional knowledge about the structure of and the intricacies of the system we wanted to reproduce and to make sound decisions about the structure of the model we were about to create.
**** how were the steps performed
in succession, with smaller additional analyses perfomed during the development process.
*** NO Step 1: analysis
**** Which analyses were performed
***** which informations of interest about our work can we retrieve
***** reconstruction of the patient-hospital interactions
***** analysis of the data exchange
***** Waveform specific analysis
Waveform analysis requires a section by itself (?)
**** Classification
**** NO How did we gather the distributions of events and interactions
of both interaction times and events intertime
*** NO Step 2: model
**** Main objectives of the generator model
reusability and extensibility
***** Why reusability and extensibility?
**** Modules of the generator model (in general)
- classification
- layered data structure
- objective usage (as a library, to be extended)
  An example usage will be showcased ...
**** Impossibilità di utilizzare valori reali

* WAIT Analysis
** Design of the analysis and preliminary steps
***
*** Postgres Container
*** Waveform (struttura del codice per ottenere i dati)
** DONE Analysis of the interactions
*** Found interactions
**** default interactions (single icustay, single admission)
**** which are the special cases found for the interactions
***** Multiple icu stays & multiple admissions :graph:
***** immediate finish after icu :graph:
***** immediate finish after icu (no posticu) :graph:
***** noicu :graph:

** DONE Classification
*** Why these classes
**** Valid
Every one of the chosen classes has a relevant presence in the dataset
**** Relevant
The classifications made "make sense" (medical relevance, probabilistic relevance (weekday))
Ethnicity would have been another relevant
*** Analysis of the patients
**** NO Marital status :graph:
**** NO Language :graph:
**** Ethnicity :graph:
**** Gender :graph:
**** Age :graph:
**** Number of admissions :graph:
*** Analysis of the admissions
** DONE Distribution fitting the interactions
*** Quale distribuzione abbiamo scelto
** Distribution fitting the events
*** Intro
- classi
- procedura standard (con esponenziale)
*** Analisi per tipologia d'evento
**** Confronto con l'esponenziale
**** Metodologia
metodologia standard + tabella
***** Casi particolari
** Distribution fitting the Waveforms
** NO Evaluation of the classification made

* DONE Simulator development
- ripeti obiettivi:
  - granularità
  - adaptability

** Scelte strutturali
- Layered Structure
- Classi e distribuzioni intercambiabili
  - Avere quanti meno hard requirements sulle classi e sulle distribuzioni possibili
  - "una soluzione che permetta una facile sostituzione delle classi"
- Manager di configurazione
Centralize the configuration

*** Diagramma UML ad alto livello
Classi principali + classificazione

*** NO Utilizzo previsto
- Override (in linea con adaptability)
- Uso su vari livelli per adattare (in linea con granularity)

** Implementazione

*** Software design choices

**** Librerie usate
- quella per generare le distribuzioni phase type (ciw)
- quella per generare le distribuzioni esponenziali (numpy)

**** Uso come libreria
Copre bene gli utilizzi previsti
In linea con un linguaggio interpretato e interattivo come python
Ci si aspetta che l'utente faccia l'override delle classi che vuole modificare.

*** Architettura specifica

**** Diagramma UML
tutte le classi + metodi usati.
Aggiunta del modulo utilities per raccogliere le funzioni utilizzate per la lettura dei file di configurazione e la generazione degli eventi

**** Sequence diagram

**** Requirements
- che le classi nei file siano le stesse descritte dalle enum

* DONE Use case
- JMT
** Reference example
Valori scelti
** Code structure
** Results

* TODO Conclusions
I dati generati riguardano solo le tempistiche, ma va bene xk possono essere usati per i modelli.

** Summary and lesson learned

** Limitations

** TODO Future Work
*** Include values other than timings
*** Coprire MIMIC-IV, il quale contiene anche le radiografie (Chest X-RAY data)
*** Clustering
[[file:analysis.org::*Choosing the classes][Choosing the classes]]
C'è da modificare anche le classi nel generatore (LIMITAZIONE). Potremmo passare una sola classe per livello (anziché admissionclass+userclass)?

*** Inclusione di altri dataset (specificatamente MIMIC-IV o ChestX-ray8 dataset)
