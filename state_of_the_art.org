#+title: State Of The Art
* Previous
** Definizioni preliminarie
- Data Lake (vedi stato dell'arte Houdal)
- Benchmark

** Obiettivo generale
Rendere possibile la valutazione delle performance di un'architettura Data Lake nell'ambito healthcare (da definire in precedenza).

Abbiamo cercato architetture esistenti(?)
Abbiamo provato cercando benchmark esistenti.

** WAIT Existing Architectures
Abbiamo provato a cercare delle implementazioni open

** Benchmarks
Ci sono sotto forma di dataset da fornire a datalake esistenti, ma o sono poco eterogenei (caratteristica focale dei datalake) o non nell'ambito healthcare

*** WAIT Bootable

*** DLBench
È un benchmark per data lakes incentrato sulla scalabilità (*come il nostro simulatore*)
# Potremmo definire il nostro lavoro in questo contesto, come parte di un benchmark più grande incentrato sulla scalabilità (?).

*** WAIT ADBench

*** BigDataBench
"For the sake of fairness, big data benchmarks must include diversity of workloads and data sets, which is the prerequisite for evaluating big data systems and architecture"

"If we want to produce numbers that are meaningful in the context of real applications, we need to use application-specific benchmarks, which in turn will need application-specific data generation tools".

**** Big data generator suite

*** NO Generation and evaluation of privacy preserving synthetic health data

**** HealthGAN

*** WAIT Big data benchmarking requirements

*** TODO On BigData Benchmarking

** Health specific data generation


** Available datasets for the medical environment

*** WAIT MIMIC-III

* New
# Preliminary term explanations
Con il termine Data Lake si intende ..

La valutazione delle performance di sistemi destinati ai Big Data è un problema che è stato affrontato in diversi ambiti e tramite diverse metodologie.
# %#TODO: descrivi data lakes e big data
Il modeling, il quale rappresenta a powerful technique to assess system performance, in quanto consente di effettuare tale valutazione astraendosi dalla specifica implementazione scelta, ne è un esempio [barbierato et al].
# %#TODO: cit barbierato et al

Una dei prerequisiti per una corretta valutazione delle performance, ancor più presente nell'ambito dei Big Data, è quella di includere in tale valutazione diversi inputs e workloads. [big data bench]
# %#TODO: cit bigdatabence
# Più in particolare, essendo il problema incentrato sulla valutazione di strutture destinate ad ospitare Data Lakes, tale necessità si accompagna a quella di utilizzare data sets _eterogenei_, che coprano quindi informazioni strutturate, semi-strutturate e non strutturate.
Questo prerequisito si traduce nella necessità di grandi volumi di dati eterogenei, composti quindi da informazioni strutturate, semi-strutturate e non strutturate.

In ogni ambito, i dataset pubblicamente disponibili composti da informazioni con forme e strutture diverse non sono molti, e per questo motivo la maggior parte degli strumenti per la performance evaluation si basano sulla _generazione dei dati_ per fornire ulteriori input ai sistemi da valutare.

Questo vale ancora di più nell'ambito dell'healthcare dove, a causa della sensibilità dei dati d'interesse, i dataset a disposizione che godono delle caratteristiche indicate sono pochi.

In questo capitolo andremo quindi ad analizzare i dataset a nostra disposizione nella Sezione~[], mostrando i vantaggi e le carenze di ciascuno, mentre analizzeremo gli strumenti esistenti per la generazione di dati da utilizzare per la valutazione delle performance di sistemi destinati ai BigData nella Sezione~[].

** Datasets
Come anticipato nella sezione precedente, i dataset a disposizione utilizzabili per la valutazione delle performance nell'ambito dei BigData e dotati quindi di dati eterogenei e di ampio volume sono pochi, e in questa sezione andremo a evidenziarne alcuni.

*** DLBench datasets
DLBench is a data-centric benchmark focused on the evaluation of data lake implementations[].
# %#TODO: citazione DLBench

Data Lakes are meant as Big Data storage systems capable of providing a "logical view of all data sources or datasets in their raw format" and that have to be "available and accessible by data scientists or statisticians to find new insights"[].
# %#TODO: citazione the next information architecture evolution: The data lake wave.

The benchmark is composed of a workload model and a data model.
The first is a set of analytical operations relevant to the context of data lakes.
The second is a set of both synthetic and real data in textual and tabular formats.

I secondi sono il focus del nostro interesse in quanto potrebbero rappresentare una valida opzione da considerare come dataset di riferimento.

I dataset presi in considerazione da DLBench sono documenti testuali e dati tabulari:
- Textual documents are scientific articles written in French and English that span from few to tens of pages and with an overall volume of 62 GB.
- Tabular data are synthetically derived from over 5000 CSV files containing Canadian government open data.

Pur rispettando la clausola dell'eterogeneità dei dati e essendo stato ideato per essere applicato all'ambito big data e data lakes, esso non è in alcun modo legato all'ambito healthcare e, per questo motivo, non è da includere tra i dataset disponibili.

*** ChestX-ray8 dataset
The ChestX-ray8 database is composed by 108948 images which are frontal-view x-ray taken from a totality of 32717 patients [cit. chestxray8] extracted from the Picture Archiving and Communication System of the National Institutes of Health.
# %#!TODO: cit chestx-ray8
Some of the X-ray image contained in the dataset has been coupled with eight disease image labels, indicating the diseas which affects the patient.
The labels have been mined from the associated radiological reports using natural language processing techniques.
Due to the nature and sensibility of the data, the reports associated with each x-ray image are not provided.

Although an incredibly useful dataset, expecially for the training of deep learning paradigms for compute-aided diagnosis systems, the lack of etherogeneity in the dataset makes it not suitable by itself for the performance evaluation of Big Data architectures.

*** MIMIC-III dataset

** Strumenti per Synthetic Data Generation
Avendo evidenziato la mancanza di dataset utilizzabili per la valutazione delle performance di Big Data systems, ci concentriamo ora sulla possibilità di generare dataset sintetici per accompagnare i dataset esistenti analizzando gli strumenti a disposizione e mostrandone i pregi e le limitazioni.

To the best of our knowledge, the only synthetic data generators capable of the production of heterogeneous data were comprised in the Big Data Generator Suite.

*** BDGS
The Big Data Generator Suite (BDGS) is a suite of data generators designed to provide input data for the evaluation of workloads in the context of a benchmark for data lake architectures called BigDataBench [cit bigdatabench] by creating synthetic data from existing datasets.

Esso è costruito per mantenere sotto controllo proprietà dei dati generati quali il loro volume, la loro varietà (intesa come le tipologie messe a disposizione) e la loro velocità (il rateo con cui tali dati sono generati), il tutto rispettando la veridicità dei dati (mantenendone cioè le caratteristiche fondamentali).

Attraverso different kinds of generators, BGDS è in grado di coprire diverse tipologie di datasets con struttura differente e campi di applicazione disparati.
Tuttavia, i campi di applicazione coperti da BGDS ad oggi sono tutti nella categoria dei servizi internet, like search engines (where the datasets used are from Wikipedia and Google), E-commerces (which uses the data provided by Amazon Movie reviews and other E-commerces), and social networks (through Facebook datasets).

Come si può notare, il tool ancora non è stato applicato a nessun ambito che si avvicini a quello medico.

# *** HealthGAN (& medGAN)
# HealthGAN is a data generation tool geared towards the generation of synthetic health-related data.

# As the name implies, it is based on Generative Adversarial Networks, an emerging technique for unsupervised learning commonly used for image synthesis and editing[cit Generative Adversarial Networks].
# # %#TODO: cit generative adversarial

# The reference dataset used for the generation of data is MIMIC-III, a publicly available dataset consisting of the medical records of multiple intensive care unit patients.[cit mimic]
# # %#TODO: cit mimic-III

# It was applied on different case studies, such as:
# - Education, for which the generator was used to produce synthetic datasets for the students of the Rensselaer Polytechnic Institute, that had to create a model capable of predicting the mortality for 20000 synthetic test patients records.
# - Research, in which the synthetic data generated by HealthGAN was used to reproduce the results of three research studies performed on MIMIC-III (namely "the impact of race on ICU mortality"[?], the "mortality of elderly patients in ICU"[?] and "mortality of Acute Kidney Injury"[?]).

# The limitation of the tool in the setting of performance evaluation is evident if we consider its outputs; the GAN, in fact, only generates a single health record per patient and, thus, is not representative of real medical records.

# For this reason, it cannot be used for our performance evvaluation purposes.

# **** Genera dati completi
# **** Non è rappresentativa in quanto genera un solo record per paziente [cit synthetic event time series]
# **** Anche lui è basato su MIMIC-III

* New New
# TODO: intro
Come evidenziato nel capitolo precedente, l'avvento dei Big Data nell'healthcare ha portato alla necessità di costruire nuovi sistemi adatti a elaborare tale nuovo carico di dati e, con essi, la necessità di valutarne le performance.

# Tuttavia, la valutazione delle performance di tali sistemi e l'assessment delle architetture necessarie per implementarli è reso difficoltoso dalla natura sensibile dei dati trattati, che quindi non possono essere facilmente reperiti per caratterizzare il carico di lavoro che il sistema dovrà supportare.

Quando si lavora con i Big Data, per effettuare una valutazione delle performance corretta e completa sorge la necessità di considerare grandi volumi di dati, che siano sia strutturati che non, e che abbiano una granularità temporale abbastanza fine da poter identificare i picchi di utilizzo del sistema in esame.

La poca abbondanza di dataset pubblicamente disponibili che rispettano queste caratteristiche causa la necessità di considerare la generazione di dati sintetici per effettuare tale valutazione.

In questo capitolo andremo quindi evidenziare, nella Sezione~[], i generatori presenti nella letteratura per l'ambito in esame.

Dato che ogni generatore di dati sintetici deve essere basato su un dataset esistente per garantire la veridicità dei dati generati, andremo anche ad analizzare i dataset disponibili nella letteratura nella Sezione~[].
Le features ricercate per questi dataset sono:
\begin{itemize}
    \item L'eterogeneità dei dati, intesa come la necessità di contenere dati strutturati, parzialmente strutturati e non strutturati.
    \item Un alto livello di granularità temporale, inteso come la necessità di analizzare eventi che avvengono anche in intervalli di tempo abbastanza brevi.
    \item Un volume di dati abbastanza grande da permettere di rendere il simulatore realistico.
\end{itemize}

** Dataset
Nella letteratura, i dataset pubblicamente disponibili con le caratteristiche ricercate sono molto pochi.

Il primo dataset considerato è stato il New Zealand National Minimal dataset, una "collection of public and private hospital discharge information, including clinical information, for inpatients and day patients" [].
Per quanto rispettasse la richiesta del volume, coprendo le degenze di tutti i pazienti degli ospedali pubblici neozelandesi dal 1993, esso non è stato ritenuto abbastanza granulare per gli scopi presentati (non contiene le osservazioni raccolte sui pazienti durante la loro degenza ma solo le informazioni registrate durante il discharge) e non abbastanza eterogeneo (contenendo solo dati tabulari).
# TODO cit new zealand national minimal dataset

Un altro dataset considerato per l'analisi è stato il dataset ChestX-ray8, a dataset of X-ray images of over 30000 patients []. Purtroppo, i radiological reports associated a ciascuna immagine non sono inclusi nel dataset, limitandone fortemente l'eterogeneità e, quindi, l'utilità.
# TODO cit chestxray8

L'unico dataset ritenuto abbastanza vasto, eterogeneo e granulare da poter essere utilizzato come riferimento per la creazione del generatore è stato MIMIC-III [].
Esso contiene i dati raccolti dall'ospedale Beth Israel di Boston nell'arco di 11 anni associati a oltre 40000 pazienti, e comprende, oltre a una grande quantità di dati tabulari strutturati rilevati e collocati temporalmente con precisione al minuto, anche le note mediche rilasciate dai caregiver dei pazienti.
Inoltre, esso è associato a un database contenente una moltitudine di segnali fisiologici rilevati durante le permanenze dei pazienti, che aumenta ancora di più l'eterogeneità del dataset.

** TODO Synthetic Generators

Una metodologia di machine learning comunemente utilizzata per la generazione di dati sintetici nell'ambito dell'healthcare sono le Generative Adversarial Networks (abbreviate a GAN).
A GAN is a kind of artificial intelligence algorithm based on an adversarial training system, where two competing models (a generator model and a discriminator model) are trained against each other [].
# TODO citazione GAN

They have been used in medGAN [], a generator that focuses on privacy preserving synthetic health data, che però è in grado di generare solo valori binari o, al più, interi, limitando fortemente la sua utilità.
# TODO: medgan (multi-label)

An evolution of medGAN is provided in healthGAN [], which is capable of the simulation of real-distributed values, rimanendo però limitato nell'eterogeneità dei dati simulati.
# healthgan generation and evaluation of privacy

In [] is proposed SmoothGAN, a new approach for the generation of high quality synthetic data that maintains important relations and factors in the original data, that is not focused on following the time distribution of the original data and that does not seem to have a functioning implementation.
# cit smoothGAN

Inoltre, in [], GANs were also used to model the MIMIC-III data set and generate heterogeneous data, but their focus was again not sulle tempistiche dei dati, che sono state omesse dall'output del generatore.
# TODO generation of heterogeneous ...

Between the synthetic data generators not based on GANs but that focus on the distribution of the data we can find Synthea [], a tool suite that focuses on the generation of health records during the entire life time of the patients, that lacks the granularity to be used for performance evaluation purposes.
# TODO SYnthea

*** Summary

In questo capitolo abbiamo mostrato la mancanza di generatori sintetici adatti alla valutazione delle performance di sistemi BigData tramite metodi di modellazione, evidenziando la loro necessità.
Abbiamo inoltre mostrato come la maggioranza dei pochi dataset a disposizione non possano essere presi come riferimento per lo sviluppo di un nuovo generatore, data la loro carenza in una o più caratteristiche necessarie.
